{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-31T19:09:24.288544Z",
     "start_time": "2025-08-31T19:09:22.660870Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import MyNeuralNet\n",
    "import matplotlib.pyplot as plt\n",
    "from lr_utils import load_dataset\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:09:24.301083Z",
     "start_time": "2025-08-31T19:09:24.294360Z"
    }
   },
   "cell_type": "code",
   "source": "train_x_orig, train_y, test_x_orig, test_y, classes = load_dataset()",
   "id": "e2b77b834e003436",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:09:24.311350Z",
     "start_time": "2025-08-31T19:09:24.307778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_x_orig_shape = train_x_orig.shape\n",
    "train_y_shape = train_y.shape\n",
    "test_x_orig_shape = test_x_orig.shape\n",
    "test_y_shape = test_y.shape\n",
    "\n",
    "print(f\"train_x_orig shape: {train_x_orig.shape} \\ntrain_y shape: {train_y.shape} \\ntest_x_orig shape: {test_x_orig.shape} \\ntest_y shape: {test_y.shape}\")"
   ],
   "id": "3076604d6f1d227f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_orig shape: (209, 64, 64, 3) \n",
      "train_y shape: (1, 209) \n",
      "test_x_orig shape: (50, 64, 64, 3) \n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:09:24.327970Z",
     "start_time": "2025-08-31T19:09:24.323564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape the training array such that each column represents an image\n",
    "train_x_orig_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T\n",
    "test_x_orig_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "print(f\"shape of train_x_orig_flatten = {train_x_orig_flatten.shape}, \\nshape of test_x_orig_flatten = {test_x_orig_flatten.shape}\")"
   ],
   "id": "460dd8e86f98c1d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_x_orig_flatten = (12288, 209), \n",
      "shape of test_x_orig_flatten = (12288, 50)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:09:24.352305Z",
     "start_time": "2025-08-31T19:09:24.342490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardize the results, ensuring to fit the learned scalar from the training set to the test set.\n",
    "train_X = train_x_orig_flatten/255.\n",
    "test_X = test_x_orig_flatten/255.\n",
    "\n",
    "print(f\"Shape of train_X: {train_X.shape} \\nShape of test_X: {test_X.shape}\")"
   ],
   "id": "2c6966512c8d034",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X: (12288, 209) \n",
      "Shape of test_X: (12288, 50)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:10:00.272036Z",
     "start_time": "2025-08-31T19:09:24.360047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let us build 2 NN's, a 2-layer NN and an L-layer NN, and compare there performance\n",
    "def neural_network(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "\n",
    "    np.random.seed(1) # Define np seed for reproducible results\n",
    "\n",
    "    NN = MyNeuralNet.NeuralNet(layers_dims) # Create NN instance, which initializes parameters.\n",
    "\n",
    "    costs = [] # Collection of costs for plotting\n",
    "\n",
    "    # repeat forward prop, back prop, and gradient descent num_iterations times.\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Extract prediction from forward prop and caches from each layer.\n",
    "        AL, caches = NN.forward_propagation(X)\n",
    "\n",
    "        # Use the prediction to compute the cost\n",
    "        cost = NN.compute_cost(AL, Y)\n",
    "\n",
    "        # perform back prop, initializing it with AL and Y.\n",
    "        grads = NN.backward_propagation(AL, Y, caches)\n",
    "\n",
    "        # Update parameter using gradient descent.\n",
    "        NN.update_parameters(grads, learning_rate)\n",
    "\n",
    "        # Print cost per 500 iterations if print_cost is true\n",
    "        if (i % 500 == 0 or i == num_iterations - 1) and print_cost == True:\n",
    "            print(f\"Cost after iteration {i}: {cost}\")\n",
    "            costs.append(cost)\n",
    "\n",
    "    return costs, NN\n",
    "\n",
    "layers_dims = [12288, 7, 1]\n",
    "costs, two_layer_NN = neural_network(train_X, train_y, layers_dims, print_cost = True)"
   ],
   "id": "df7b2f48d1a40227",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.7074426632736273\n",
      "Cost after iteration 500: 0.3336897138438556\n",
      "Cost after iteration 1000: 0.12412486168658173\n",
      "Cost after iteration 1500: 0.05362667055856123\n",
      "Cost after iteration 2000: 0.03330274414524972\n",
      "Cost after iteration 2500: 0.02306424025583977\n",
      "Cost after iteration 2999: 0.016151946179173104\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:10:00.289602Z",
     "start_time": "2025-08-31T19:10:00.280654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predictions for train and test with the two layer NN.\n",
    "predictions_train = two_layer_NN.predict(train_X)\n",
    "predictions_test = two_layer_NN.predict(test_X)\n",
    "\n",
    "# Select the first row of each array to make them 1D. Calculate accuracy for 2 layer NN\n",
    "accuracy_train = accuracy_score(predictions_train[0], train_y[0])\n",
    "accuracy_test = accuracy_score(predictions_test[0], test_y[0])\n",
    "print(f\"2 layer NN: \\nAccuracy_train: {100 * accuracy_train:.2f}% \\nAccuracy_test: {100 * accuracy_test:.2f}%\")"
   ],
   "id": "b47d28ddbb30ea6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 layer NN: \n",
      "Accuracy_train: 100.00% \n",
      "Accuracy_test: 74.00%\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:10:44.110794Z",
     "start_time": "2025-08-31T19:10:00.303728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set structure for the 4 layer NN\n",
    "layers_dims = [12288, 20, 7, 5, 1]\n",
    "\n",
    "# Train model.\n",
    "costs, four_layer_NN = neural_network(train_X, train_y, layers_dims, print_cost = True)"
   ],
   "id": "18d155af423c47d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.208125010600323\n",
      "Cost after iteration 500: 0.647319447526937\n",
      "Cost after iteration 1000: 0.6374058448197395\n",
      "Cost after iteration 1500: 0.6243486119913269\n",
      "Cost after iteration 2000: 0.5391408405511141\n",
      "Cost after iteration 2500: 0.2998273840124648\n",
      "Cost after iteration 2999: 0.08237974441376025\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T19:10:44.127406Z",
     "start_time": "2025-08-31T19:10:44.118685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predictions for train and test with the four layer NN.\n",
    "predictions_train = four_layer_NN.predict(train_X)\n",
    "predictions_test = four_layer_NN.predict(test_X)\n",
    "\n",
    "# Select the first row of each array to make them 1D. Calculate accuracy for 4 layer NN\n",
    "accuracy_train = accuracy_score(predictions_train[0], train_y[0])\n",
    "accuracy_test = accuracy_score(predictions_test[0], test_y[0])\n",
    "\n",
    "print(f\"4 layer NN: \\nAccuracy_train: {100 * accuracy_train:.2f}% \\nAccuracy_test: {100 * accuracy_test:.2f}%\")"
   ],
   "id": "754ed230b45eb7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 layer NN: \n",
      "Accuracy_train: 100.00% \n",
      "Accuracy_test: 80.00%\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# In this notebook I learned how to implement He initialization and why it is important when using\n",
    "# ReLu as our primary activation function. I also learned how to generalize my code to enable and\n",
    "# account for deeper NNs."
   ],
   "id": "d508167a9d6811b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
